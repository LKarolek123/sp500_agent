{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load labeled dataset and initial features\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "df = pd.read_csv('data/processed/sp500_features_labeled.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "FEATURES = [c for c in df.columns if c not in ('label','signal')]\n",
    "print('Features:', FEATURES)\n",
    "print('Rows:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa46e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Permutation importance (uses trained model)\n",
    "from src.models.feature_analysis import run as perm_run\n",
    "perm_run()\n",
    "from IPython.display import Image, display\n",
    "display(Image('logs/perm_importance.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47657a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) SHAP summary (if generated)\n",
    "import os\n",
    "shap_path = Path('logs/shap_summary.png')\n",
    "if shap_path.exists():\n",
    "    display(Image(str(shap_path)))\n",
    "else:\n",
    "    print('SHAP summary not available. Run src/models/feature_analysis with SHAP installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Simple iterative feature selection: drop weakest permutation feature and retrain XGBoost\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def retrain_and_eval(df, features):\n",
    "    X = df[features]\n",
    "    y = df['label']\n",
    "    n = len(df)\n",
    "    train_end = int(0.7 * n)\n",
    "    val_end = train_end + int(0.15 * n)\n",
    "    X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
    "    X_test, y_test = X.iloc[val_end:], y.iloc[val_end:]\n",
    "    # class weighting on original labels\n",
    "    classes = list(y_train.unique())\n",
    "    try:\n",
    "        cw = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "        weight_map = {cls: w for cls, w in zip(classes, cw)}\n",
    "        sample_weight = y_train.map(weight_map).values\n",
    "    except Exception:\n",
    "        sample_weight = None\n",
    "    model = XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.05, use_label_encoder=False, eval_metric='mlogloss')\n",
    "    model.fit(X_train, y_train.map({v:i for i,v in enumerate(sorted(y_train.unique()))}), sample_weight=sample_weight, verbose=False)\n",
    "    preds = pd.Series(model.predict(X_test)).map({i:v for i,v in enumerate(sorted(y_train.unique()))})\n",
    "    print(classification_report(y_test, preds, digits=4))\n",
    "    return model\n",
    "\n",
    "# Run iterative drop: (caution: retraining multiple times)\n",
    "features = FEATURES.copy()\n",
    "# limit iterations to avoid long runs\n",
    "for step in range(3):\n",
    "    print('Iteration', step, 'features count', len(features))\n",
    "    m = retrain_and_eval(df, features)\n",
    "    # compute simple feature importance from model and drop weakest\n",
    "    imp = m.feature_importances_\n",
    "    weakest = features[int(imp.argmin())]\n",
    "    print('Dropping weakest feature:', weakest)\n",
    "    features.remove(weakest)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
